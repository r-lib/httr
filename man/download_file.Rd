% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/download-file.R
\name{download_file}
\alias{download_file}
\title{Download file from the Internet (cache-aware)}
\usage{
download_file(url, path, overwrite = FALSE, ...)
}
\arguments{
\item{url}{the url(s) of the file to retrieve. If multiple URLs are provided then the same
number of \link{path}s must also be provided.}

\item{path}{Path(s) to save content to. If more than one \code{path} is specified then the same
number of \link{url}s must also be provided. THis parameter will be \code{\link[=path.expand]{path.expand()}}ed.}

\item{overwrite}{Will only overwrite existing path if \code{TRUE}.}

\item{...}{passed on to \code{\link[=GET]{GET()}}}
}
\value{
a data frame containing the \code{url}(s), \code{path}(s), cache status, and HTTP status code(s).
If there was an error downloading a file the path, status code, and HTTP status
columns will be \code{NA}. If the file was now re-downloaded the status code will be 399
}
\description{
This is an alternative to \code{\link[utils:download.file]{utils::download.file()}} and a convenience wrapper for
\code{\link[=GET]{GET()}} + \code{\link[httr:write_disk]{httr::write_disk()}} to perform file downloads.
}
\details{
Since this function uses \code{\link[=GET]{GET()}}, callers can pass in \code{httr} configuration
options to customize the behaviour of the download process (e.g. specify a \code{User-Agent} via
\code{\link[=user_agent]{user_agent()}}, set proxy config via \code{\link[=use_proxy]{use_proxy()}}, etc.).

The function is also "cache-aware" in the sense that you deliberately have to specify
\code{overwrite = TRUE} to force a re-download. This has the potential to save bandwidth
of both the caller and the site hosting files for download.
}
\note{
While this function supports specifying multiple URLs and download paths it
does not perform concurrent downloads.
}
\examples{
tmp1 <- tempfile()
tmp2 <- tempfile()
tmp3 <- tempfile()

download_file("https://google.com", tmp1) # downloads fine
download_file("https://google.com", tmp1) # doesn't re-download since it's cached
download_file("https://google.com", tmp1, overwrite = TRUE) # re-downloads (overwrites file)
download_file("https://google.com", tmp2) # re-downloads (new file)
download_file("badurl", tmp3) # handles major errors gracefully

# multi-file example with no-caching
download_file(
  c(rep("https://google.com", 2), "badurl"),
  c(tmp1, tmp2, tmp3),
  overwrite = TRUE
)

# multi-file example with caching
download_file(
  c(rep("https://google.com", 2), "badurl"),
  c(tmp1, tmp2, tmp3),
  overwrite = FALSE
)
}
\seealso{
\code{\link[=GET]{GET()}}; \code{\link[=write_disk]{write_disk()}}
}
